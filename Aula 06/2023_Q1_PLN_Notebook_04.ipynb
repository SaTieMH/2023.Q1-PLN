{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLwYZLKKomYrnLd3Fc3Np7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2023.Q1-PLN/blob/main/2023_Q1_PLN_Notebook_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q1]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmK05FgcOzL2"
      },
      "source": [
        "## **Modelo de Linguagem com N-gramas**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um modelo de linguagem com n-gramas é um tipo de modelo estatístico usado em PLN para prever a probabilidade de uma sequência de palavras ocorrer em um determinado contexto.\n",
        "\n",
        "O \"n\" em \"n-grama\" refere-se ao número de palavras que o modelo leva em consideração de cada vez para fazer suas previsões. Por exemplo, em um modelo de linguagem de n-grama de 3, o modelo usa 3 palavras consecutivas para fazer suas previsões.\n",
        "\n",
        "O modelo de linguagem com n-gramas funciona calculando a probabilidade condicional de uma palavra dada as n-1 palavras anteriores. Isso é conhecido como modelo de Markov de ordem n-1, onde n-1 é o número de palavras que o modelo leva em consideração para prever a próxima palavra."
      ],
      "metadata": {
        "id": "YKeqSx2qOxPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos supor que temos o seguinte conjunto de frases:\n",
        "\n",
        "    \"Eu gosto de estudar matemática.\"\n",
        "    \"Matemática é minha matéria favorita na escola.\"\n",
        "    \"Eu sempre tive dificuldade em matemática.\"\n",
        "\n",
        "Podemos usar um modelo de linguagem com n-gramas para prever a probabilidade de uma palavra aparecer dado o contexto de palavras que a antecedem. Por exemplo, se usarmos um modelo de linguagem com n-gramas de 2, podemos calcular a probabilidade de uma palavra aparecer dado a palavra anterior.\n",
        "\n",
        "Assim, se quisermos prever a próxima palavra após \"Eu gosto de\", usamos o modelo de linguagem com n-gramas de 2 para calcular a probabilidade condicional da próxima palavra, que seria:\n",
        "\n",
        "    Probabilidade de \"estudar\" dado \"Eu gosto de\" = 1/1 = 100%\n",
        "    Probabilidade de \"ler\" dado \"Eu gosto de\" = 0/1 = 0%\n",
        "\n",
        "Nesse caso, o modelo prevê que a próxima palavra após \"Eu gosto de\" será \"estudar\" com 100% de probabilidade, já que é a única palavra que aparece após esse conjunto de palavras nas frases fornecidas.\n",
        "\n",
        "Esse é apenas um exemplo simplificado para ilustrar como um modelo de linguagem com n-gramas funciona na prática. Na prática, usamos modelos mais complexos com um grande número de frases e palavras para criar modelos de linguagem mais precisos."
      ],
      "metadata": {
        "id": "Wfor8fHiB4hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK**"
      ],
      "metadata": {
        "id": "6EyG4LSJMBV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ver um exemplo de como extrair n-gramas usando a biblioteca `NLTK` em Python. Suponha que temos o seguinte texto:"
      ],
      "metadata": {
        "id": "cRqaGyVoMM-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"O cachorro correu pelo parque e brincou com a bola.\""
      ],
      "metadata": {
        "id": "oCOwJ1wNMFRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos extrair os bigramas (2-gramas) do texto da seguinte maneira:"
      ],
      "metadata": {
        "id": "Q8LbvyZ1Maqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "# tokenização do texto\n",
        "tokenized_text = text.split()\n",
        "\n",
        "# criação dos bigramas\n",
        "bigrams = ngrams(tokenized_text, 2)\n",
        "\n",
        "# exibição dos bigramas\n",
        "for bigram in bigrams:\n",
        "    print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFfzlbX4MbyX",
        "outputId": "450609ce-3710-4895-bcb6-d3f6375ca7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('O', 'cachorro')\n",
            "('cachorro', 'correu')\n",
            "('correu', 'pelo')\n",
            "('pelo', 'parque')\n",
            "('parque', 'e')\n",
            "('e', 'brincou')\n",
            "('brincou', 'com')\n",
            "('com', 'a')\n",
            "('a', 'bola.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De maneira similar, podemos extrair trigramas e quadrigramas, por exemplo:"
      ],
      "metadata": {
        "id": "KoRirr6cOJUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criação dos trigramas\n",
        "trigrams = ngrams(tokenized_text, 3)\n",
        "\n",
        "# exibição dos trigramas\n",
        "for trigram in trigrams:\n",
        "    print(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJcOB_zOMqgm",
        "outputId": "3127127e-fd62-4321-cc54-12851bef46c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('O', 'cachorro', 'correu')\n",
            "('cachorro', 'correu', 'pelo')\n",
            "('correu', 'pelo', 'parque')\n",
            "('pelo', 'parque', 'e')\n",
            "('parque', 'e', 'brincou')\n",
            "('e', 'brincou', 'com')\n",
            "('brincou', 'com', 'a')\n",
            "('com', 'a', 'bola.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criação dos quadrigramas\n",
        "quadrigrams = ngrams(tokenized_text, 4)\n",
        "\n",
        "# exibição dos quadrigramas\n",
        "for quadrigram in quadrigrams:\n",
        "    print(quadrigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJreVWOaMspC",
        "outputId": "0a9bbfb2-2a6c-41b0-c4a6-79013a3dad04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('O', 'cachorro', 'correu', 'pelo')\n",
            "('cachorro', 'correu', 'pelo', 'parque')\n",
            "('correu', 'pelo', 'parque', 'e')\n",
            "('pelo', 'parque', 'e', 'brincou')\n",
            "('parque', 'e', 'brincou', 'com')\n",
            "('e', 'brincou', 'com', 'a')\n",
            "('brincou', 'com', 'a', 'bola.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TextBlob**"
      ],
      "metadata": {
        "id": "76gY7cvLNU7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"O cachorro correu pelo parque e brincou com a bola.\"\n",
        "blob = TextBlob(text)\n",
        "\n",
        "# criação dos bigramas\n",
        "bigrams = list(blob.ngrams(2))\n",
        "\n",
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R0bXRFVNz90",
        "outputId": "bb9105a3-9702-4865-ae6f-bd842e8b069c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WordList(['O', 'cachorro']), WordList(['cachorro', 'correu']), WordList(['correu', 'pelo']), WordList(['pelo', 'parque']), WordList(['parque', 'e']), WordList(['e', 'brincou']), WordList(['brincou', 'com']), WordList(['com', 'a']), WordList(['a', 'bola'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criação dos trigramas\n",
        "trigrams = list(blob.ngrams(3))\n",
        "\n",
        "print(trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24yPe9bVN5yp",
        "outputId": "d32e6002-7be9-4037-d4ab-87998192b818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WordList(['O', 'cachorro', 'correu']), WordList(['cachorro', 'correu', 'pelo']), WordList(['correu', 'pelo', 'parque']), WordList(['pelo', 'parque', 'e']), WordList(['parque', 'e', 'brincou']), WordList(['e', 'brincou', 'com']), WordList(['brincou', 'com', 'a']), WordList(['com', 'a', 'bola'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scikit-learn**"
      ],
      "metadata": {
        "id": "p6Q4wXkBQew5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está um exemplo simples de como extrair bigramas usando a biblioteca `Scikit-learn` em Python:"
      ],
      "metadata": {
        "id": "NR9qP5XJQ_Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# define os documentos de exemplo\n",
        "documents = [\"o cachorro correu pelo parque\",\n",
        "             \"o cachorro brincou com a bola\",\n",
        "             \"a bola era azul\"]\n",
        "\n",
        "# cria o vetorizador de n-gramas\n",
        "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "# extrai os bigramas\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# imprime os bigramas\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgVEQsVMQ50w",
        "outputId": "7f51828c-ca87-4ecc-f63c-4e61fdc9b93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bola era' 'brincou com' 'cachorro brincou' 'cachorro correu' 'com bola'\n",
            " 'correu pelo' 'era azul' 'pelo parque']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste exemplo, usamos a classe `CountVectorizer` da biblioteca `Scikit-learn` para criar um vetorizador de bigramas a partir de uma lista de documentos de exemplo. Passamos o argumento `ngram_range=(2,2)` para especificar que queremos bigramas, e chamamos o método `fit_transform `para extrair os bigramas dos documentos.\n",
        "\n",
        "Finalmente, imprimimos os bigramas usando o método `get_feature_names_out` do vetorizador."
      ],
      "metadata": {
        "id": "90Q72nPsRTau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está um exemplo simples de como extrair trigramas usando a biblioteca `Scikit-learn` em Python:"
      ],
      "metadata": {
        "id": "knt3wt5HRF6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# define os documentos de exemplo\n",
        "documents = [\"o cachorro correu pelo parque\",\n",
        "             \"o cachorro brincou com a bola\",\n",
        "             \"a bola era azul\"]\n",
        "\n",
        "# cria o vetorizador de n-gramas\n",
        "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
        "\n",
        "# extrai os trigramas\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# imprime os trigramas\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P5HjmfNQgWF",
        "outputId": "68dc69e8-dd16-4325-fdfb-7193abd8c564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bola era azul' 'brincou com bola' 'cachorro brincou com'\n",
            " 'cachorro correu pelo' 'correu pelo parque']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está um exemplo de como extrair unigramas e bigramas usando a biblioteca `Scikit-learn` em Python:"
      ],
      "metadata": {
        "id": "N9Jz8kUoR9K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# define as avaliações de exemplo\n",
        "reviews = [\"Este filme é incrível, recomendo para todos!\", \n",
        "           \"Muito bom, gostei bastante\", \n",
        "           \"Não gostei muito do filme, achei meio parado\", \n",
        "           \"Uma experiência horrível, não assistam!\", \n",
        "           \"Maravilhoso, não vejo a hora de assistir de novo!\"]\n",
        "\n",
        "# cria o vetorizador de unigramas e bigramas\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "# extrai os unigramas e bigramas de todas as avaliações\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "\n",
        "# imprime os unigramas e bigramas extraídos\n",
        "print(\"Unigramas e bigramas extraídos:\")\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_i-6u1jR1vE",
        "outputId": "17ae708a-2e83-4084-a8e5-493de0794709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigramas e bigramas extraídos:\n",
            "['achei' 'achei meio' 'assistam' 'assistir' 'assistir de' 'bastante' 'bom'\n",
            " 'bom gostei' 'de' 'de assistir' 'de novo' 'do' 'do filme' 'este'\n",
            " 'este filme' 'experiência' 'experiência horrível' 'filme' 'filme achei'\n",
            " 'filme incrível' 'gostei' 'gostei bastante' 'gostei muito' 'hora'\n",
            " 'hora de' 'horrível' 'horrível não' 'incrível' 'incrível recomendo'\n",
            " 'maravilhoso' 'maravilhoso não' 'meio' 'meio parado' 'muito' 'muito bom'\n",
            " 'muito do' 'novo' 'não' 'não assistam' 'não gostei' 'não vejo' 'para'\n",
            " 'para todos' 'parado' 'recomendo' 'recomendo para' 'todos' 'uma'\n",
            " 'uma experiência' 'vejo' 'vejo hora']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exemplos**\n",
        "---"
      ],
      "metadata": {
        "id": "xdEMV1i9PDS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suponha que temos o seguinte conjunto de dados:"
      ],
      "metadata": {
        "id": "xHB17bHDKLxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"o rato roeu a roupa do rei de roma\", \n",
        "        \"uma casa de papel\",   \n",
        "        \"o gato comeu o queijo\",    \n",
        "        \"o cachorro late muito\",    \n",
        "        \"o cavalo galopa livremente\",    \n",
        "        \"a janela quebrou\",    \n",
        "        \"a porta está aberta\"]\n"
      ],
      "metadata": {
        "id": "ZCHiBDglJ3Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nosso objetivo é construir um modelo de linguagem com base nos n-gramas dessas frases e usá-lo para prever a próxima palavra em uma dada frase.\n",
        "\n",
        "Para isso, vamos usar a biblioteca NLTK em Python para tokenizar as frases em palavras e construir os n-gramas."
      ],
      "metadata": {
        "id": "SHmY4W7hKiub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phkdn4AKJ-kM",
        "outputId": "9cc08179-1ba5-49b9-c240-c66fa6c740d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "# tokenização das frases\n",
        "tokenized_data = [nltk.word_tokenize(sentence) for sentence in data]\n",
        "\n",
        "# criação dos bigramas\n",
        "bigrams = []\n",
        "for sentence in tokenized_data:\n",
        "    sentence_bigrams = ngrams(sentence, 2)\n",
        "    bigrams.extend(sentence_bigrams)\n",
        "\n",
        "# contagem dos bigramas\n",
        "bigram_counts = Counter(bigrams)\n",
        "\n",
        "# cálculo das probabilidades condicionais\n",
        "def predict_next_word(word, bigram_counts):\n",
        "    possible_next_words = []\n",
        "    for bigram in bigram_counts:\n",
        "        if bigram[0] == word:\n",
        "            possible_next_words.append((bigram[1], bigram_counts[bigram]))\n",
        "    return possible_next_words"
      ],
      "metadata": {
        "id": "vtJwAR73J6ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste exemplo, estamos construindo um modelo de bigramas e testando-o com a palavra \"rato\". O modelo retorna uma lista de possíveis palavras seguintes, juntamente com a frequência de cada bigrama observado na base de dados:"
      ],
      "metadata": {
        "id": "R26W6ijELwtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# teste do modelo\n",
        "print(predict_next_word(\"rato\", bigram_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSYdPCUaKrkJ",
        "outputId": "e6977520-0205-46ec-bb80-0f83eb0b855b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('roeu', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está outro exemplo que usa um modelo de linguagem com bigramas para prever a próxima palavra em uma frase:"
      ],
      "metadata": {
        "id": "XnFnuXMWY9dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkJlrvpzZBUV",
        "outputId": "b0f8850a-1f99-4543-c3bd-74c75cc86ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "\n",
        "# Texto de exemplo\n",
        "text = \"O rato roeu a roupa do rei de Roma. E a rainha ficou só.\"\n",
        "\n",
        "# Treinar modelo de linguagem com bigramas\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "for w1, w2 in bigrams:\n",
        "    model[w1][w2] += 1\n",
        "\n",
        "# Prever a próxima palavra em uma frase\n",
        "def predict_next_word(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "    last_word = tokens[-1]\n",
        "    next_word_probabilities = model[last_word]\n",
        "    if len(next_word_probabilities) == 0:\n",
        "        return None\n",
        "    return max(next_word_probabilities, key=next_word_probabilities.get)\n",
        "\n",
        "# Prever a próxima palavra em uma frase de exemplo\n",
        "sentence = \"O rato roeu a roupa do\"\n",
        "next_word = predict_next_word(sentence)\n",
        "print(f\"A próxima palavra em '{sentence}' é '{next_word}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq6GlTcSY8xC",
        "outputId": "5f7df556-3c10-41c3-a479-b73372306c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A próxima palavra em 'O rato roeu a roupa do' é 'rei'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está um exemplo que usa um modelo de linguagem com trigramas para prever a próxima palavra com base em duas palavras anteriores:"
      ],
      "metadata": {
        "id": "a9MemtUOaauD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Texto de exemplo\n",
        "text = \"O rato roeu a roupa do rei de Roma. E a rainha ficou só.\"\n",
        "\n",
        "# Tokenizar palavras e criar trigramas\n",
        "tokens = nltk.word_tokenize(text.lower())\n",
        "trigrams = list(nltk.trigrams(tokens))\n",
        "\n",
        "# Criar dicionário de trigramas com suas frequências\n",
        "trigram_counts = {}\n",
        "for trigram in trigrams:\n",
        "    if trigram[:2] not in trigram_counts:\n",
        "        trigram_counts[trigram[:2]] = {}\n",
        "    if trigram[2] not in trigram_counts[trigram[:2]]:\n",
        "        trigram_counts[trigram[:2]][trigram[2]] = 0\n",
        "    trigram_counts[trigram[:2]][trigram[2]] += 1\n",
        "\n",
        "# Função para prever próxima palavra com base em duas palavras anteriores\n",
        "def predict_next_word(prev_word1, prev_word2):\n",
        "    if (prev_word1, prev_word2) not in trigram_counts:\n",
        "        return None\n",
        "    next_word = max(trigram_counts[(prev_word1, prev_word2)], key=trigram_counts[(prev_word1, prev_word2)].get)\n",
        "    return next_word\n",
        "\n",
        "# Testar a função com algumas palavras\n",
        "print(predict_next_word('a', 'roupa'))\n",
        "print(predict_next_word('o', 'rato'))\n",
        "print(predict_next_word('de', 'roma'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG0s-AhWaT5b",
        "outputId": "162113c9-d5b7-4154-a949-dbe41d15dff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "do\n",
            "roeu\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamoso criar um modelo de linguagem com n-gramas usando a biblioteca `NLTK` do Python."
      ],
      "metadata": {
        "id": "XjN0NOqrFyX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para começar, precisamos importar as bibliotecas necessárias e fazer o download dos dados e pacotes do `NLTK`:"
      ],
      "metadata": {
        "id": "hHyg7lOiFPkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISriJqHwFExm",
        "outputId": "9bdafcf6-5d63-4cf9-fa53-38804230a45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, vamos criar uma lista de sentenças de exemplo para treinar nosso modelo:"
      ],
      "metadata": {
        "id": "cMzeWwGaF7fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"O cachorro late para a lua.\",  \n",
        "             \"A lua é branca como a neve.\",  \n",
        "             \"O sol é amarelo e brilhante.\",   \n",
        "             \"O cachorro é o melhor amigo do homem.\",  \n",
        "             \"A lua é o satélite natural da Terra.\",   \n",
        "             \"O cachorro corre pelo parque.\",  \n",
        "             \"O sol nasce no leste e se põe no oeste.\",  \n",
        "             \"A lua cheia é linda no céu noturno.\",   \n",
        "             \"O cachorro abana o rabo quando está feliz.\"]"
      ],
      "metadata": {
        "id": "P3ijEJPWFUHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos criar uma função que irá receber uma lista de sentenças e um valor de n (o tamanho do n-grama) e retornar um modelo de linguagem com n-gramas:"
      ],
      "metadata": {
        "id": "MyYpTJYSGAkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams, FreqDist\n",
        "\n",
        "def create_ngram_model(sentences, n):\n",
        "    # Inicializar um dicionário vazio para armazenar a frequência dos n-gramas\n",
        "    ngram_freq = {}\n",
        "    \n",
        "    # Iterar sobre as sentenças e gerar n-gramas\n",
        "    for sentence in sentences:\n",
        "        # Quebrar a sentença em tokens\n",
        "        tokens = nltk.word_tokenize(sentence.lower())\n",
        "        \n",
        "        # Gerar n-gramas\n",
        "        ngrams_list = list(ngrams(tokens, n))\n",
        "        \n",
        "        # Iterar sobre os n-gramas e adicionar à frequência\n",
        "        for ngram in ngrams_list:\n",
        "            if ngram in ngram_freq:\n",
        "                ngram_freq[ngram] += 1\n",
        "            else:\n",
        "                ngram_freq[ngram] = 1\n",
        "    \n",
        "    # Calcular a frequência relativa de cada n-grama\n",
        "    for ngram in ngram_freq:\n",
        "        ngram_freq[ngram] /= len(ngram_freq)\n",
        "    \n",
        "    # Retornar um objeto FreqDist com as frequências relativas dos n-gramas\n",
        "    return FreqDist(ngram_freq)"
      ],
      "metadata": {
        "id": "YU3BTOOoFfHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, podemos usar a função para criar um modelo de linguagem com n-gramas de tamanho 2 (bigramas) a partir das sentenças de exemplo:"
      ],
      "metadata": {
        "id": "f7hTZSWHGGrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_ngram_model(sentences, 2)"
      ],
      "metadata": {
        "id": "A3MB-HCjFiNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos usar o modelo para gerar uma lista dos bigramas mais comuns:"
      ],
      "metadata": {
        "id": "clRPZSPKGL2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC4OXsQ3FlLv",
        "outputId": "e8b618b1-829b-4932-839c-f29e44e30d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('o', 'cachorro'), 0.07017543859649122), (('a', 'lua'), 0.07017543859649122), (('lua', 'é'), 0.03508771929824561), (('o', 'sol'), 0.03508771929824561), (('é', 'o'), 0.03508771929824561), (('cachorro', 'late'), 0.017543859649122806), (('late', 'para'), 0.017543859649122806), (('para', 'a'), 0.017543859649122806), (('lua', '.'), 0.017543859649122806), (('é', 'branca'), 0.017543859649122806)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isso gera uma lista dos 10 bigramas mais comuns no corpus de exemplo, juntamente com suas frequências relativas."
      ],
      "metadata": {
        "id": "yeWe_uz4GOi4"
      }
    }
  ]
}